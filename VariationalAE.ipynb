{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSY59y8Eu_8Z"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mariyamuneeb/ssl_wordspotting/blob/main/VariationalAE.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAvHGaA63gPE"
      },
      "source": [
        "## Project Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj2iCMvuNyYO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "!git clone https://github.com/mariyamuneeb/ssl_wordspotting\n",
        "os.chdir('/content/ssl_wordspotting')\n",
        "!pip install -qqq wandb\n",
        "\n",
        "from setup_wandb import wandb_login\n",
        "wandb_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:15:56.923475Z",
          "start_time": "2023-01-22T13:15:53.952995Z"
        },
        "id": "AQcW98vJ8B_Y"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt # plotting library\n",
        "import numpy as np # this module is useful to work with numerical arrays\n",
        "import pandas as pd \n",
        "import random \n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import wandb\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oo4UDu_qV5O"
      },
      "source": [
        "# Standard Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nyjQvgh22_S"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrSkWjm1a1RJ"
      },
      "outputs": [],
      "source": [
        "num_channels = 3\n",
        "base_channel_size=32\n",
        "lr = 10e-2\n",
        "latent_dim = 384\n",
        "epochs = 300\n",
        "plot_freq = 10\n",
        "\n",
        "wandb.init(\n",
        "      # Set the project where this run will be logged\n",
        "      project=\"SSL\", \n",
        "      # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
        "      name=f\"VAE\", \n",
        "      # Track hyperparameters and run metadata\n",
        "      config={\n",
        "      \"architecture\": \"CNN\",\n",
        "      \"dataset\": \"CIFAR-10\",\n",
        "      \"epochs\": epochs,\n",
        "      \"latent_dim\":latent_dim\n",
        "      })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6FoQuN853ip"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "# d = 4\n",
        "\n",
        "vae = VariationalAutoencoder(latent_dims=4)\n",
        "\n",
        "optim = torch.optim.Adam(vae.parameters(), lr=lr)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Selected device: {device}')\n",
        "\n",
        "vae.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J1cgQvs3s-O"
      },
      "source": [
        "## Import/Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGl005fo8RZM"
      },
      "outputs": [],
      "source": [
        "data_dir = 'dataset'\n",
        "# train_dataset = torchvision.datasets.MNIST(data_dir, train = True, download = True)\n",
        "# test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(data_dir,train=True,download=True)\n",
        "test_dataset  = torchvision.datasets.CIFAR10(data_dir,train=False, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brvR2L49xNMW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsgnrzo2KzQA"
      },
      "outputs": [],
      "source": [
        "img = train_dataset[1][0]\n",
        "label = train_dataset[1][1]\n",
        "print(img.mode)\n",
        "print(label)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J81ybJ2Wml-o"
      },
      "outputs": [],
      "source": [
        "img.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SlmWgwP8tWc"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([transforms.ToTensor(), ])\n",
        "\n",
        "test_transform = transforms.Compose([transforms.ToTensor(), ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJf4FmL-9E7E"
      },
      "outputs": [],
      "source": [
        "train_dataset.transform = train_transform\n",
        "test_dataset.transform = test_transform\n",
        "\n",
        "m=len(train_dataset)\n",
        "\n",
        "train_data, val_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])\n",
        "batch_size=256\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q074Zmjj9bPG"
      },
      "source": [
        "VariationalAutoencoder class, which combines the Encoder and Decoder classes \n",
        "The encoder and decoder networks contain **three convolutional layers** and **two fully connected layers**. \n",
        "Some batch normal layers are added to have more robust features in the latent space. \n",
        "Differently from the standard autoencoder, the **encoder returns mean and variance matrices** and we use them to obtain the sampled latent vector. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93a6o1jq3OHs"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwUn0p7S9U3e"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "   train_loss = train_epoch(vae,device,train_loader,optim)\n",
        "   val_loss = test_epoch(vae,device,valid_loader)\n",
        "   print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, epochs,train_loss,val_loss))\n",
        "   if epoch%plot_freq==0:\n",
        "       plot_ae_outputs(vae.encoder,vae.decoder,n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m0ufLwUVtrT"
      },
      "outputs": [],
      "source": [
        "break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8qkBjedVngN"
      },
      "outputs": [],
      "source": [
        "train_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO2dYAoMoV7N"
      },
      "source": [
        "# VAE on Hand-written Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYQ-39cjHT5o"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZknEdk_r_kqt"
      },
      "source": [
        "### Connect to GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5jN5BN_-cBw"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH = '/content/drive/MyDrive/Datasets/tif'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZidUqcI_sgL"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MysQxraoeTzI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "from math import floor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOF8HLNQ_zee"
      },
      "source": [
        "### Custom Dataset Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slV_LJ0-AIaY"
      },
      "outputs": [],
      "source": [
        "images_paths = [os.path.join(PATH,i) for i in os.listdir(PATH)]\n",
        "split = 0.85\n",
        "train_idx = math.floor(split*len(images_paths))\n",
        "train_images = images_paths[:train_idx]\n",
        "test_images = images_paths[train_idx:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqLz_mGNBRn9"
      },
      "source": [
        "### Plotting Few Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BreM58fbBO-D"
      },
      "outputs": [],
      "source": [
        "random_imgs = random.sample(train_images, 9)\n",
        "random_imgs = [Image.open(i) for i in random_imgs]\n",
        "_, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
        "axs = axs.flatten()\n",
        "for img, ax in zip(random_imgs, axs):\n",
        "    ax.imshow(img)\n",
        "    ax.title.set_text(f'Image Shape {img.size},{img.mode}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB-qzqetELqW"
      },
      "source": [
        "### Finding Ave Image Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-jxGkyXESt8"
      },
      "outputs": [],
      "source": [
        "h_list = list()\n",
        "w_list = list()\n",
        "\n",
        "for p in train_images:\n",
        "    h_list.append(Image.open(p).size[1])\n",
        "    w_list.append(Image.open(p).size[0])\n",
        "num_channels = int(Image.open(p).mode)\n",
        "\n",
        "h_ave = floor(mean(h_list))\n",
        "w_ave = floor(mean(w_list))\n",
        "# resize_size = (h_ave,w_ave)\n",
        "resize_size = (128,128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chw7hy3hz95m"
      },
      "source": [
        "### Dataset Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzWS8sYNnxkT"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Resize(resize_size),])\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Resize(resize_size),])\n",
        "\n",
        "hw_train_dataset = MyDataset(img_paths=train_images,transform=train_transform)\n",
        "hw_test_dataset = MyDataset(img_paths=test_images,transform=test_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0R17Iq4HIKw"
      },
      "source": [
        "### Dataloader and Batching Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA8qrO3PHdiK"
      },
      "outputs": [],
      "source": [
        "m=len(hw_train_dataset)\n",
        "\n",
        "\n",
        "batch_size=8\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(hw_train_dataset, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(hw_test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG3GD4JO0INN"
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:19:08.602612Z",
          "start_time": "2023-01-22T13:19:08.586896Z"
        },
        "id": "oAEo-8l70Ktj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8zuJMXv_KK8"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0pqFiZIu_9J"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T11:19:05.358802Z",
          "start_time": "2023-01-22T11:19:05.353833Z"
        },
        "id": "Vw9QQcCC_KK-"
      },
      "outputs": [],
      "source": [
        "base_channel_size = 32\n",
        "lr = 1e-3\n",
        "latent_dim = 512\n",
        "epochs = 300\n",
        "plot_freq = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COtz1mTVKD1m"
      },
      "outputs": [],
      "source": [
        "hw_train_dataset[0][0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l-sFOl8GXnl"
      },
      "source": [
        "### W&B Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUv8GX5WGW3C"
      },
      "outputs": [],
      "source": [
        "wandb.init(\n",
        "      # Set the project where this run will be logged\n",
        "      project=\"SSL\", \n",
        "      # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
        "      name=f\"VAE\", \n",
        "      # Track hyperparameters and run metadata\n",
        "      config={\n",
        "      \"architecture\": \"CNN\",\n",
        "      \"dataset\": \"Hand Written Dataset\",\n",
        "      \"lr\":lr,\n",
        "      \"epochs\": epochs,\n",
        "      \"latent_dim\":latent_dim\n",
        "      })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft3OLrMd_KLC"
      },
      "source": [
        "### Initialize VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frlAmJr1_KLE"
      },
      "source": [
        "Initialize the VariationalAutoencoder class, the optimizer, and the device to use the GPU in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8wALQrK_KLF"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "vae = VariationalAutoencoder(num_channels,base_channel_size,latent_dim)\n",
        "print(vae)\n",
        "\n",
        "optim = torch.optim.Adam(vae.parameters(), lr=lr)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Selected device: {device}')\n",
        "vae.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JR2TvqtIStx"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqhaSG1lIWhq"
      },
      "source": [
        "### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T11:17:05.010949Z",
          "start_time": "2023-01-22T11:17:05.006278Z"
        },
        "id": "hX_doqxrIVJW"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "   train_loss = train_epoch(vae,device,train_loader,optim)\n",
        "   val_loss = test_epoch(vae,device,valid_loader)\n",
        "   print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, epochs,train_loss,val_loss))\n",
        "   if epoch%plot_freq==0:\n",
        "       plot_ae_custom_ds_outputs(vae.encoder,vae.decoder,hw_test_dataset,n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMUgJJWl7ryg",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# IAM Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KT02E0-u_9P"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:20:48.913307Z",
          "start_time": "2023-01-22T13:20:48.907008Z"
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4cnqB0xau_9P"
      },
      "outputs": [],
      "source": [
        "from models.dataset_utils import IAMDataset\n",
        "from PIL import Image\n",
        "from math import floor\n",
        "from statistics import mean"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy Dataset to Colab Instance"
      ],
      "metadata": {
        "id": "ZK-kf3og4mPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from data_utils.utils import copy_iam_dataset_to_colab\n",
        "copy_iam_dataset_to_colab()"
      ],
      "metadata": {
        "id": "X9_zF79BzhVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/ssl_wordspotting/data/words_training'\n",
        "test_dir = '/content/ssl_wordspotting/data/words_test'"
      ],
      "metadata": {
        "id": "klnVjxRU28_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:15:45.403362Z",
          "start_time": "2023-01-22T13:15:45.296090Z"
        },
        "id": "-2eX4W4Pu_9Q"
      },
      "outputs": [],
      "source": [
        "resize_size = (128,128)\n",
        "train_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Resize(resize_size),])\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Resize(resize_size),])\n",
        "iam_train_dataset = IAMDataset(train_dir,transform=train_transform)\n",
        "iam_test_dataset = IAMDataset(test_dir,transform=train_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Few Samples"
      ],
      "metadata": {
        "id": "OfmuQzts5YPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from data_utils.plotting import plot_samples,plot_reconstructions\n",
        "plot_samples(iam_train_dataset,9)"
      ],
      "metadata": {
        "id": "Ztfg91mb5OwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:17:55.194171Z",
          "start_time": "2023-01-22T13:17:55.188510Z"
        },
        "id": "dXvj8NNHu_9Q"
      },
      "outputs": [],
      "source": [
        "batch_size=256\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(iam_train_dataset, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(iam_test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edJTS35pu_9T"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujBtQDmFu_9T"
      },
      "source": [
        "### HyperParameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:18:31.486979Z",
          "start_time": "2023-01-22T13:18:31.481712Z"
        },
        "id": "UA2wtpKMu_9T"
      },
      "outputs": [],
      "source": [
        "base_channel_size = 32\n",
        "num_channels = 3\n",
        "lr = 1e-3\n",
        "latent_dim = 512\n",
        "epochs = 300\n",
        "plot_freq = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhI4y6dmu_9U"
      },
      "source": [
        "### W&B Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:18:41.276449Z",
          "start_time": "2023-01-22T13:18:33.880504Z"
        },
        "id": "3zqft9glu_9V"
      },
      "outputs": [],
      "source": [
        "wandb.init(\n",
        "      # Set the project where this run will be logged\n",
        "      project=\"SSL\", \n",
        "      # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
        "      name=f\"IAM VAE\", \n",
        "      # Track hyperparameters and run metadata\n",
        "      config={\n",
        "      \"architecture\": \"CNN\",\n",
        "      \"dataset\": \"IAM Hand Written Dataset\",\n",
        "      \"lr\":lr,\n",
        "      \"epochs\": epochs,\n",
        "      \"latent_dim\":latent_dim\n",
        "      })"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r7RdrqEXr6MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JujgaDLmu_9V"
      },
      "source": [
        "### Initialize VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:22:34.287662Z",
          "start_time": "2023-01-22T13:22:34.155825Z"
        },
        "id": "bgYkvruyu_9W"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "vae = VariationalAutoencoder(num_channels,base_channel_size,latent_dim)\n",
        "\n",
        "vae.to(device)\n",
        "optim = torch.optim.Adam(vae.parameters(), lr=lr)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Selected device: {device}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0kCI6hpu_9W"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVFUGu9du_9W"
      },
      "source": [
        "### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:22:41.894928Z",
          "start_time": "2023-01-22T13:22:41.761712Z"
        },
        "id": "RlD_DSoJu_9W"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "   train_loss = train_epoch(vae,device,train_loader,optim)\n",
        "   val_loss = test_epoch(vae,device,valid_loader)\n",
        "   print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, epochs,train_loss,val_loss))\n",
        "   if epoch%plot_freq==0:\n",
        "       plot_reconstructions(vae.encoder,vae.decoder,iam_test_dataset,device, n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNcUeZxTu_9Y"
      },
      "outputs": [],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JFLaBqYir7Jv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "zAvHGaA63gPE",
        "93a6o1jq3OHs"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}