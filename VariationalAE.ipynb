{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSY59y8Eu_8Z",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mariyamuneeb/ssl_wordspotting/blob/main/VariationalAE.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAvHGaA63gPE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wj2iCMvuNyYO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "!git clone https://github.com/mariyamuneeb/ssl_wordspotting\n",
    "os.chdir('/content/ssl_wordspotting')\n",
    "!pip install -qqq wandb\n",
    "\n",
    "from setup_wandb import wandb_login\n",
    "wandb_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T13:15:56.923475Z",
     "start_time": "2023-01-22T13:15:53.952995Z"
    },
    "id": "AQcW98vJ8B_Y",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _imaging: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m \u001B[38;5;66;03m# plotting library\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m \u001B[38;5;66;03m# this module is useful to work with numerical arrays\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m \n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:109\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpackaging\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse \u001B[38;5;28;01mas\u001B[39;00m parse_version\n\u001B[0;32m    107\u001B[0m \u001B[38;5;66;03m# cbook must import matplotlib only within function\u001B[39;00m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;66;03m# definitions, so it is safe to import from it here.\u001B[39;00m\n\u001B[1;32m--> 109\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, _version, cbook, docstring, rcsetup\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcbook\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MatplotlibDeprecationWarning, sanitize_sequence\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcbook\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mplDeprecation  \u001B[38;5;66;03m# deprecated\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py:27\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, cbook\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcbook\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ls_mapper\n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolors\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Colormap, is_color_like\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfontconfig_pattern\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse_fontconfig_pattern\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_enums\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m JoinStyle, CapStyle\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\colors.py:51\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumbers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Number\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n\u001B[1;32m---> 51\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mPngImagePlugin\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PngInfo\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpl\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py:89\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     80\u001B[0m MAX_IMAGE_PIXELS \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m4\u001B[39m \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001B[39;00m\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001B[39;00m\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;66;03m# import Image and use the Image.core variable instead.\u001B[39;00m\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001B[39;00m\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;66;03m# and should be considered private and subject to change.\u001B[39;00m\n\u001B[1;32m---> 89\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _imaging \u001B[38;5;28;01mas\u001B[39;00m core\n\u001B[0;32m     91\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m __version__ \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(core, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPILLOW_VERSION\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     92\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m     93\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe _imaging extension was built for another version of Pillow or PIL:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     94\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCore version: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mgetattr\u001B[39m(core, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPILLOW_VERSION\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     95\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPillow version: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     96\u001B[0m         )\n",
      "\u001B[1;31mImportError\u001B[0m: DLL load failed while importing _imaging: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd \n",
    "import random \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oo4UDu_qV5O",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Standard Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nyjQvgh22_S",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrSkWjm1a1RJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_channels = 3\n",
    "base_channel_size=32\n",
    "lr = 10e-2\n",
    "latent_dim = 384\n",
    "epochs = 300\n",
    "plot_freq = 10\n",
    "\n",
    "wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"SSL\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"VAE\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"architecture\": \"CNN\",\n",
    "      \"dataset\": \"CIFAR-10\",\n",
    "      \"epochs\": epochs,\n",
    "      \"latent_dim\":latent_dim\n",
    "      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6FoQuN853ip",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# d = 4\n",
    "\n",
    "vae = VariationalAutoencoder(latent_dims=4)\n",
    "\n",
    "optim = torch.optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "vae.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6J1cgQvs3s-O",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import/Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGl005fo8RZM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = 'dataset'\n",
    "# train_dataset = torchvision.datasets.MNIST(data_dir, train = True, download = True)\n",
    "# test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(data_dir,train=True,download=True)\n",
    "test_dataset  = torchvision.datasets.CIFAR10(data_dir,train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brvR2L49xNMW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dsgnrzo2KzQA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = train_dataset[1][0]\n",
    "label = train_dataset[1][1]\n",
    "print(img.mode)\n",
    "print(label)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J81ybJ2Wml-o",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SlmWgwP8tWc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.ToTensor(), ])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor(), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJf4FmL-9E7E",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset.transform = train_transform\n",
    "test_dataset.transform = test_transform\n",
    "\n",
    "m=len(train_dataset)\n",
    "\n",
    "train_data, val_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])\n",
    "batch_size=256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q074Zmjj9bPG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "VariationalAutoencoder class, which combines the Encoder and Decoder classes \n",
    "The encoder and decoder networks contain **three convolutional layers** and **two fully connected layers**. \n",
    "Some batch normal layers are added to have more robust features in the latent space. \n",
    "Differently from the standard autoencoder, the **encoder returns mean and variance matrices** and we use them to obtain the sampled latent vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93a6o1jq3OHs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwUn0p7S9U3e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "   train_loss = train_epoch(vae,device,train_loader,optim)\n",
    "   val_loss = test_epoch(vae,device,valid_loader)\n",
    "   print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, epochs,train_loss,val_loss))\n",
    "   if epoch%plot_freq==0:\n",
    "       plot_ae_outputs(vae.encoder,vae.decoder,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2m0ufLwUVtrT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8qkBjedVngN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO2dYAoMoV7N",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# VAE on Hand-written Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYQ-39cjHT5o",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZknEdk_r_kqt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Connect to GDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5jN5BN_-cBw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "PATH = '/content/drive/MyDrive/Datasets/tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZidUqcI_sgL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MysQxraoeTzI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOF8HLNQ_zee",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Custom Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slV_LJ0-AIaY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images_paths = [os.path.join(PATH,i) for i in os.listdir(PATH)]\n",
    "split = 0.85\n",
    "train_idx = math.floor(split*len(images_paths))\n",
    "train_images = images_paths[:train_idx]\n",
    "test_images = images_paths[train_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqLz_mGNBRn9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plotting Few Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BreM58fbBO-D",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_imgs = random.sample(train_images, 9)\n",
    "random_imgs = [Image.open(i) for i in random_imgs]\n",
    "_, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
    "axs = axs.flatten()\n",
    "for img, ax in zip(random_imgs, axs):\n",
    "    ax.imshow(img)\n",
    "    ax.title.set_text(f'Image Shape {img.size},{img.mode}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oB-qzqetELqW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Finding Ave Image Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-jxGkyXESt8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "h_list = list()\n",
    "w_list = list()\n",
    "\n",
    "for p in train_images:\n",
    "    h_list.append(Image.open(p).size[1])\n",
    "    w_list.append(Image.open(p).size[0])\n",
    "num_channels = int(Image.open(p).mode)\n",
    "\n",
    "h_ave = floor(mean(h_list))\n",
    "w_ave = floor(mean(w_list))\n",
    "# resize_size = (h_ave,w_ave)\n",
    "resize_size = (128,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chw7hy3hz95m",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataset Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JzWS8sYNnxkT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Resize(resize_size),])\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Resize(resize_size),])\n",
    "\n",
    "hw_train_dataset = MyDataset(img_paths=train_images,transform=train_transform)\n",
    "hw_test_dataset = MyDataset(img_paths=test_images,transform=test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0R17Iq4HIKw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataloader and Batching Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wA8qrO3PHdiK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m=len(hw_train_dataset)\n",
    "\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(hw_train_dataset, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(hw_test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yG3GD4JO0INN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T13:19:08.602612Z",
     "start_time": "2023-01-22T13:19:08.586896Z"
    },
    "id": "oAEo-8l70Ktj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8zuJMXv_KK8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0pqFiZIu_9J",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T11:19:05.358802Z",
     "start_time": "2023-01-22T11:19:05.353833Z"
    },
    "id": "Vw9QQcCC_KK-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_channel_size = 32\n",
    "lr = 1e-3\n",
    "latent_dim = 512\n",
    "epochs = 300\n",
    "plot_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COtz1mTVKD1m",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hw_train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l-sFOl8GXnl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### W&B Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUv8GX5WGW3C",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"SSL\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"VAE\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"architecture\": \"CNN\",\n",
    "      \"dataset\": \"Hand Written Dataset\",\n",
    "      \"lr\":lr,\n",
    "      \"epochs\": epochs,\n",
    "      \"latent_dim\":latent_dim\n",
    "      })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ft3OLrMd_KLC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Initialize VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frlAmJr1_KLE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initialize the VariationalAutoencoder class, the optimizer, and the device to use the GPU in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8wALQrK_KLF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "vae = VariationalAutoencoder(num_channels,base_channel_size,latent_dim)\n",
    "print(vae)\n",
    "\n",
    "optim = torch.optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "vae.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JR2TvqtIStx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqhaSG1lIWhq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T11:17:05.010949Z",
     "start_time": "2023-01-22T11:17:05.006278Z"
    },
    "id": "hX_doqxrIVJW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "   train_loss = train_epoch(vae,device,train_loader,optim)\n",
    "   val_loss = test_epoch(vae,device,valid_loader)\n",
    "   print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, epochs,train_loss,val_loss))\n",
    "   if epoch%plot_freq==0:\n",
    "       plot_ae_custom_ds_outputs(vae.encoder,vae.decoder,hw_test_dataset,n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMUgJJWl7ryg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# IAM Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KT02E0-u_9P",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T13:20:48.913307Z",
     "start_time": "2023-01-22T13:20:48.907008Z"
    },
    "id": "4cnqB0xau_9P",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IAMDataset2\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m floor\n",
      "File \u001B[1;32m~\\PycharmProjects\\ssl_wordspotting\\models\\dataset_utils.py:3\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpathlib\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dataset, DataLoader\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from models.dataset_utils import IAMDataset2\n",
    "from PIL import Image\n",
    "from math import floor\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZK-kf3og4mPW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Copy Dataset to Colab Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9_zF79BzhVn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from data_utils.utils import copy_iam_dataset_to_colab\n",
    "copy_iam_dataset_to_colab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klnVjxRU28_e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = '/content/ssl_wordspotting/data/words_training'\n",
    "test_dir = '/content/ssl_wordspotting/data/words_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T13:15:45.403362Z",
     "start_time": "2023-01-22T13:15:45.296090Z"
    },
    "id": "-2eX4W4Pu_9Q",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resize_size = (128,128)\n",
    "train_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Resize(resize_size),])\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Resize(resize_size),])\n",
    "iam_train_dataset = IAMDataset(train_dir,transform=train_transform)\n",
    "iam_test_dataset = IAMDataset(test_dir,transform=train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfmuQzts5YPZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot Few Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ztfg91mb5OwC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from data_utils.plotting import plot_samples,plot_reconstructions\n",
    "plot_samples(iam_train_dataset,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T13:17:55.194171Z",
     "start_time": "2023-01-22T13:17:55.188510Z"
    },
    "id": "dXvj8NNHu_9Q",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(iam_train_dataset, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(iam_test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_channel_size = 32\n",
    "num_channels = 3\n",
    "lr = 1e-3\n",
    "latent_dim = 512\n",
    "epochs = 300\n",
    "plot_freq = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### W&B Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"SSL\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"IAM VAE\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"architecture\": \"CNN\",\n",
    "      \"dataset\": \"IAM Hand Written Dataset\",\n",
    "      \"lr\":lr,\n",
    "      \"epochs\": epochs,\n",
    "      \"latent_dim\":latent_dim\n",
    "      })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, num_channels, base_channel_size, latent_dim):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.encoder = VariationalEncoder(num_channels, base_channel_size, latent_dim)\n",
    "        self.decoder = Decoder(num_channels, base_channel_size, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Initialize VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "vae = VariationalAutoencoder(num_channels,base_channel_size,latent_dim)\n",
    "\n",
    "vae.to(device)\n",
    "optim = torch.optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "   train_loss = train_epoch(vae,device,train_loader,optim)\n",
    "   val_loss = test_epoch(vae,device,valid_loader)\n",
    "   print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, epochs,train_loss,val_loss))\n",
    "   if epoch%plot_freq==0:\n",
    "       plot_reconstructions(vae.encoder,vae.decoder,iam_test_dataset,device, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edJTS35pu_9T",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujBtQDmFu_9T",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T13:18:31.486979Z",
     "start_time": "2023-01-22T13:18:31.481712Z"
    },
    "id": "UA2wtpKMu_9T",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_channel_size = 32\n",
    "num_channels = 3\n",
    "lr = 1e-3\n",
    "latent_dim = 512\n",
    "epochs = 300\n",
    "plot_freq = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhI4y6dmu_9U",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### W&B Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T13:18:41.276449Z",
     "start_time": "2023-01-22T13:18:33.880504Z"
    },
    "id": "3zqft9glu_9V",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"SSL\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"IAM VAE\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"architecture\": \"CNN\",\n",
    "      \"dataset\": \"IAM Hand Written Dataset\",\n",
    "      \"lr\":lr,\n",
    "      \"epochs\": epochs,\n",
    "      \"latent_dim\":latent_dim\n",
    "      })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBvAyENwBixB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ider61saBhBP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, num_channels, base_channel_size, latent_dim):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.encoder = VariationalEncoder(num_channels, base_channel_size, latent_dim)\n",
    "        self.decoder = Decoder(num_channels, base_channel_size, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JujgaDLmu_9V",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Initialize VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T13:22:34.287662Z",
     "start_time": "2023-01-22T13:22:34.155825Z"
    },
    "id": "bgYkvruyu_9W",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "vae = VariationalAutoencoder(num_channels,base_channel_size,latent_dim)\n",
    "\n",
    "vae.to(device)\n",
    "optim = torch.optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0kCI6hpu_9W",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVFUGu9du_9W",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T13:22:41.894928Z",
     "start_time": "2023-01-22T13:22:41.761712Z"
    },
    "id": "RlD_DSoJu_9W",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(vae,device,train_loader,optim)\n",
    "    val_loss = test_epoch(vae,device,valid_loader)\n",
    "    \n",
    "    print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, epochs,train_loss,val_loss))\n",
    "    if epoch%plot_freq==0:\n",
    "        plot_reconstructions(vae.encoder,vae.decoder,iam_test_dataset,device, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eNcUeZxTu_9Y",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFLaBqYir7Jv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "zAvHGaA63gPE",
    "93a6o1jq3OHs"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}