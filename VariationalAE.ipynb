{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSY59y8Eu_8Z",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mariyamuneeb/ssl_wordspotting/blob/main/VariationalAE.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAvHGaA63gPE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Project Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-08T13:02:34.762300Z",
          "start_time": "2023-05-08T13:02:34.599628Z"
        },
        "id": "wj2iCMvuNyYO",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import os\n",
        "!git clone https://github.com/mariyamuneeb/ssl_wordspotting\n",
        "os.chdir('/content/ssl_wordspotting')\n",
        "!pip install -qqq wandb\n",
        "\n",
        "from setup_wandb import wandb_login\n",
        "wandb_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FV_zMTSCZTD3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:15:56.923475Z",
          "start_time": "2023-01-22T13:15:53.952995Z"
        },
        "id": "AQcW98vJ8B_Y",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt # plotting library\n",
        "import numpy as np # this module is useful to work with numerical arrays\n",
        "import pandas as pd \n",
        "import random \n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import wandb\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oo4UDu_qV5O",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Standard Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nyjQvgh22_S",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrSkWjm1a1RJ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "num_channels = 3\n",
        "base_channel_size=32\n",
        "lr = 10e-2\n",
        "latent_dim = 384\n",
        "epochs = 300\n",
        "plot_freq = 10\n",
        "\n",
        "wandb.init(\n",
        "      # Set the project where this run will be logged\n",
        "      project=\"SSL\", \n",
        "      # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
        "      name=f\"VAE\", \n",
        "      # Track hyperparameters and run metadata\n",
        "      config={\n",
        "      \"architecture\": \"CNN\",\n",
        "      \"dataset\": \"CIFAR-10\",\n",
        "      \"epochs\": epochs,\n",
        "      \"latent_dim\":latent_dim\n",
        "      })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6FoQuN853ip",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "# d = 4\n",
        "\n",
        "vae = VariationalAutoencoder(latent_dims=4)\n",
        "\n",
        "optim = torch.optim.Adam(vae.parameters(), lr=lr)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Selected device: {device}')\n",
        "\n",
        "vae.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J1cgQvs3s-O",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Import/Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGl005fo8RZM",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data_dir = 'dataset'\n",
        "# train_dataset = torchvision.datasets.MNIST(data_dir, train = True, download = True)\n",
        "# test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(data_dir,train=True,download=True)\n",
        "test_dataset  = torchvision.datasets.CIFAR10(data_dir,train=False, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brvR2L49xNMW",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsgnrzo2KzQA",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "img = train_dataset[1][0]\n",
        "label = train_dataset[1][1]\n",
        "print(img.mode)\n",
        "print(label)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J81ybJ2Wml-o",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "img.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SlmWgwP8tWc",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([transforms.ToTensor(), ])\n",
        "\n",
        "test_transform = transforms.Compose([transforms.ToTensor(), ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJf4FmL-9E7E",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "train_dataset.transform = train_transform\n",
        "test_dataset.transform = test_transform\n",
        "\n",
        "m=len(train_dataset)\n",
        "\n",
        "train_data, val_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])\n",
        "batch_size=256\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q074Zmjj9bPG",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "VariationalAutoencoder class, which combines the Encoder and Decoder classes \n",
        "The encoder and decoder networks contain **three convolutional layers** and **two fully connected layers**. \n",
        "Some batch normal layers are added to have more robust features in the latent space. \n",
        "Differently from the standard autoencoder, the **encoder returns mean and variance matrices** and we use them to obtain the sampled latent vector. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93a6o1jq3OHs",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwUn0p7S9U3e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "   train_loss = train_epoch(vae,device,train_loader,optim)\n",
        "   val_loss = test_epoch(vae,device,valid_loader)\n",
        "   print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, epochs,train_loss,val_loss))\n",
        "   if epoch%plot_freq==0:\n",
        "       plot_ae_outputs(vae.encoder,vae.decoder,n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m0ufLwUVtrT",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8qkBjedVngN",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "train_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO2dYAoMoV7N",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# VAE on Hand-written Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYQ-39cjHT5o",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZknEdk_r_kqt",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Connect to GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5jN5BN_-cBw",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH = '/content/drive/MyDrive/Datasets/tif'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZidUqcI_sgL",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MysQxraoeTzI",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "from math import floor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOF8HLNQ_zee",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Custom Dataset Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slV_LJ0-AIaY",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "images_paths = [os.path.join(PATH,i) for i in os.listdir(PATH)]\n",
        "split = 0.85\n",
        "train_idx = math.floor(split*len(images_paths))\n",
        "train_images = images_paths[:train_idx]\n",
        "test_images = images_paths[train_idx:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqLz_mGNBRn9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Plotting Few Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BreM58fbBO-D",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "random_imgs = random.sample(train_images, 9)\n",
        "random_imgs = [Image.open(i) for i in random_imgs]\n",
        "_, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
        "axs = axs.flatten()\n",
        "for img, ax in zip(random_imgs, axs):\n",
        "    ax.imshow(img)\n",
        "    ax.title.set_text(f'Image Shape {img.size},{img.mode}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB-qzqetELqW",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Finding Ave Image Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-jxGkyXESt8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "h_list = list()\n",
        "w_list = list()\n",
        "\n",
        "for p in train_images:\n",
        "    h_list.append(Image.open(p).size[1])\n",
        "    w_list.append(Image.open(p).size[0])\n",
        "num_channels = int(Image.open(p).mode)\n",
        "\n",
        "h_ave = floor(mean(h_list))\n",
        "w_ave = floor(mean(w_list))\n",
        "# resize_size = (h_ave,w_ave)\n",
        "resize_size = (128,128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chw7hy3hz95m",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Dataset Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzWS8sYNnxkT",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Resize(resize_size),])\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Resize(resize_size),])\n",
        "\n",
        "hw_train_dataset = MyDataset(img_paths=train_images,transform=train_transform)\n",
        "hw_test_dataset = MyDataset(img_paths=test_images,transform=test_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0R17Iq4HIKw",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Dataloader and Batching Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA8qrO3PHdiK",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "m=len(hw_train_dataset)\n",
        "\n",
        "\n",
        "batch_size=8\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(hw_train_dataset, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(hw_test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG3GD4JO0INN",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:19:08.602612Z",
          "start_time": "2023-01-22T13:19:08.586896Z"
        },
        "id": "oAEo-8l70Ktj",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8zuJMXv_KK8",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0pqFiZIu_9J",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T11:19:05.358802Z",
          "start_time": "2023-01-22T11:19:05.353833Z"
        },
        "id": "Vw9QQcCC_KK-",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "base_channel_size = 32\n",
        "lr = 1e-3\n",
        "latent_dim = 512\n",
        "epochs = 300\n",
        "plot_freq = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COtz1mTVKD1m",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "hw_train_dataset[0][0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l-sFOl8GXnl",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### W&B Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUv8GX5WGW3C",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "wandb.init(\n",
        "      # Set the project where this run will be logged\n",
        "      project=\"SSL\", \n",
        "      # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
        "      name=f\"VAE\", \n",
        "      # Track hyperparameters and run metadata\n",
        "      config={\n",
        "      \"architecture\": \"CNN\",\n",
        "      \"dataset\": \"Hand Written Dataset\",\n",
        "      \"lr\":lr,\n",
        "      \"epochs\": epochs,\n",
        "      \"latent_dim\":latent_dim\n",
        "      })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft3OLrMd_KLC",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Initialize VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frlAmJr1_KLE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Initialize the VariationalAutoencoder class, the optimizer, and the device to use the GPU in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8wALQrK_KLF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "vae = VariationalAutoencoder(num_channels,base_channel_size,latent_dim)\n",
        "print(vae)\n",
        "\n",
        "optim = torch.optim.Adam(vae.parameters(), lr=lr)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Selected device: {device}')\n",
        "vae.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JR2TvqtIStx",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqhaSG1lIWhq",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T11:17:05.010949Z",
          "start_time": "2023-01-22T11:17:05.006278Z"
        },
        "id": "hX_doqxrIVJW",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "   train_loss = train_epoch(vae,device,train_loader,optim)\n",
        "   val_loss = test_epoch(vae,device,valid_loader)\n",
        "   print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, epochs,train_loss,val_loss))\n",
        "   if epoch%plot_freq==0:\n",
        "       plot_ae_custom_ds_outputs(vae.encoder,vae.decoder,hw_test_dataset,n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMUgJJWl7ryg",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# IAM Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KT02E0-u_9P",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:20:48.913307Z",
          "start_time": "2023-01-22T13:20:48.907008Z"
        },
        "id": "4cnqB0xau_9P",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from models.dataset import IAMDataset2,IAMDataset,IAMSubset\n",
        "from models.layers import VariationalEncoder,Decoder\n",
        "from experiment_utils.utils import train_epoch,test_epoch\n",
        "from PIL import Image\n",
        "from math import floor\n",
        "from statistics import mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK-kf3og4mPW",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Copy Dataset to Colab Instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9_zF79BzhVn",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from data_utils.utils import copy_iam_dataset_to_colab\n",
        "copy_iam_dataset_to_colab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klnVjxRU28_e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# train_dir = '/content/ssl_wordspotting/data/words_training'\n",
        "# test_dir = '/content/ssl_wordspotting/data/words_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:15:45.403362Z",
          "start_time": "2023-01-22T13:15:45.296090Z"
        },
        "id": "-2eX4W4Pu_9Q",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "resize_size = (128,128)\n",
        "train_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Resize(resize_size),])\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Resize(resize_size),])\n",
        "iam_train_dataset = IAMDataset2('train',transform=train_transform)\n",
        "iam_test_dataset = IAMDataset2('test',transform=train_transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MENhKEtWeaKi",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "subset_iam_train_dataset = IAMSubset().subset(iam_train_dataset,0.2)\n",
        "subset_iam_test_dataset = IAMSubset().subset(iam_test_dataset,0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfmuQzts5YPZ",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Plot Few Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ztfg91mb5OwC",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from data_utils.plotting import plot_iam_samples,plot_reconstructions,plot_iam_reconstructions\n",
        "# plot_iam_samples(iam_train_dataset,9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-22T13:17:55.194171Z",
          "start_time": "2023-01-22T13:17:55.188510Z"
        },
        "id": "dXvj8NNHu_9Q",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "batch_size=256\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(subset_iam_train_dataset, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(subset_iam_test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lUnRpbjZTE2",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ob8_oQZZTE2",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### HyperParameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEzDhVvjZTE3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "base_channel_size = 32\n",
        "num_channels = 3\n",
        "lr = 1e-3\n",
        "latent_dim = 512\n",
        "epochs = 150\n",
        "plot_freq = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y25IV8-HZTE3",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### W&B Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpjExjd4ZTE4",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "wandb.init(\n",
        "      # Set the project where this run will be logged\n",
        "      project=\"SSL\", \n",
        "      # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
        "      name=f\"IAM VAE\", \n",
        "      # Track hyperparameters and run metadata\n",
        "      config={\n",
        "      \"architecture\": \"CNN\",\n",
        "      \"dataset\": \"IAM Hand Written Dataset\",\n",
        "      \"lr\":lr,\n",
        "      \"epochs\": epochs,\n",
        "      \"latent_dim\":latent_dim\n",
        "      })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1TgpD6TZTE4",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Define VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S-PunUtZTE6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, num_channels, base_channel_size, latent_dim):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.encoder = VariationalEncoder(num_channels, base_channel_size, latent_dim)\n",
        "        self.decoder = Decoder(num_channels, base_channel_size, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_RjmG17ZTE6",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Initialize VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdbABrhBZTE7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "vae = VariationalAutoencoder(num_channels,base_channel_size,latent_dim)\n",
        "\n",
        "vae.to(device)\n",
        "optim = torch.optim.Adam(vae.parameters(), lr=lr)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Selected device: {device}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnYw4qdGZTE8",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKeMKv8tZTFH",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byLnY8i7ZTFI",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "   train_loss = train_epoch(vae,device,train_loader,optim)\n",
        "   val_loss = test_epoch(vae,device,valid_loader)\n",
        "   print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, epochs,train_loss,val_loss))\n",
        "   if epoch%plot_freq==0:\n",
        "       plot_reconstructions(vae.encoder,vae.decoder,iam_test_dataset,device, n=10)\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KbNPrArZTFJ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X02ZVTx4ZTFJ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edJTS35pu_9T",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujBtQDmFu_9T",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### HyperParameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CG5Kp_rW0bs6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "base_channel_size = 32\n",
        "num_channels = 1\n",
        "lr = 1e-3\n",
        "latent_dim = 512\n",
        "epochs = 150\n",
        "plot_freq = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAQ1SCbk0bs7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### W&B Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XYr-ZQX0bs8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "wandb.init(\n",
        "      # Set the project where this run will be logged\n",
        "      project=\"SSL\", \n",
        "      # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
        "      name=f\"IAM VAE\", \n",
        "      # Track hyperparameters and run metadata\n",
        "      config={\n",
        "      \"architecture\": \"CNN\",\n",
        "      \"dataset\": \"IAM Hand Written Dataset\",\n",
        "      \"lr\":lr,\n",
        "      \"epochs\": epochs,\n",
        "      \"latent_dim\":latent_dim\n",
        "      })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq0c1CJG0bs-",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Define VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca3j-1VH0bs-",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, num_channels, base_channel_size, latent_dim):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.encoder = VariationalEncoder(num_channels, base_channel_size, latent_dim)\n",
        "        self.decoder = Decoder(num_channels, base_channel_size, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbOdUWZ-0bs_",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Initialize VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-b8pNVi0btA",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "vae = VariationalAutoencoder(num_channels,base_channel_size,latent_dim)\n",
        "\n",
        "vae.to(device)\n",
        "optim = torch.optim.Adam(vae.parameters(), lr=lr)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Selected device: {device}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSCADha40btA",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU5JKm3O0btC",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOW4kMEZ0btD",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "    train_loss = train_epoch(vae,device,train_loader,optim)\n",
        "    val_loss = test_epoch(vae,device,valid_loader)\n",
        "    \n",
        "    print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, epochs,train_loss,val_loss))\n",
        "    if epoch%plot_freq==0:\n",
        "        plot_iam_reconstructions(vae.encoder,vae.decoder,iam_test_dataset,device,'IAM HW', n=10)\n",
        "        \n",
        "        ## save model here\n",
        "        ## run evaluation of MAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNcUeZxTu_9Y",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "PATH = '/content/drive/MyDrive/Mariyah_Phd/weights/vae_weights.pt'\n",
        "torch.save(model, PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "j4LZsSJX7txY"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CXQ31buy7txZ"
      },
      "outputs": [],
      "source": [
        "def plot_iam_reconstructions(encoder, decoder, test_dataset, device, dataset_name, n=10):\n",
        "    wandb_imgs = list()\n",
        "    wandb_rec_imgs = list()\n",
        "    my_table = wandb.Table(columns=[\"Original\", \"Reconstruction\"])\n",
        "    plt.figure(figsize=(16, 4.5))\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        _, img, _ = test_dataset[i]\n",
        "        img = img.unsqueeze(0).to(device)\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        with torch.no_grad():\n",
        "            rec_img = decoder(encoder(img))\n",
        "        plt.imshow(img.cpu().squeeze().numpy().T, cmap='gist_gray')  # for MNIST remove the transpose\n",
        "        #   plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray') # for MNIST remove the transpose\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        if i == n // 2:\n",
        "            ax.set_title('Original images')\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(rec_img.cpu().squeeze().numpy().T, cmap='gist_gray')  # for MNIST remove the transpose\n",
        "        #   plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  #for MNIST remove the transpose\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        if i == n // 2:\n",
        "            ax.set_title('Reconstructed images')\n",
        "        my_table.add_data(wandb.Image(img.cpu()), wandb.Image(rec_img.cpu()))\n",
        "        wandb_imgs.append(img.cpu())\n",
        "        wandb_rec_imgs.append(rec_img.cpu())\n",
        "    plt.show()\n",
        "    wandb.log({dataset_name: my_table})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eiCDdcKf7txa"
      },
      "outputs": [],
      "source": [
        "plot_iam_reconstructions(vae.encoder,vae.decoder,subset_iam_test_dataset,device,'IAM HW', n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HyHRvq-F7txa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hWEjp-4B7txb"
      },
      "outputs": [],
      "source": [
        "def plot_iam_reconstructions(encoder, decoder, test_dataset, device, dataset_name, n=10):\n",
        "    wandb_imgs = list()\n",
        "    wandb_rec_imgs = list()\n",
        "    my_table = wandb.Table(columns=[\"Original\", \"Reconstruction\"])\n",
        "    plt.figure(figsize=(16, 4.5))\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        _, img, _ = test_dataset[i]\n",
        "        img = img.unsqueeze(0).to(device)\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        with torch.no_grad():\n",
        "            rec_img = decoder(encoder(img))\n",
        "        plt.imshow(img.cpu().squeeze().numpy().T, cmap='gist_gray')  # for MNIST remove the transpose\n",
        "        #   plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray') # for MNIST remove the transpose\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        if i == n // 2:\n",
        "            ax.set_title('Original images')\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(rec_img.cpu().squeeze().numpy().T, cmap='gist_gray')  # for MNIST remove the transpose\n",
        "        #   plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  #for MNIST remove the transpose\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        if i == n // 2:\n",
        "            ax.set_title('Reconstructed images')\n",
        "        my_table.add_data(wandb.Image(img.cpu()), wandb.Image(rec_img.cpu()))\n",
        "        wandb_imgs.append(img.cpu())\n",
        "        wandb_rec_imgs.append(rec_img.cpu())\n",
        "    plt.show()\n",
        "    wandb.log({dataset_name: my_table})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "spxsiFQw7txb"
      },
      "outputs": [],
      "source": [
        "plot_iam_reconstructions(vae.encoder,vae.decoder,subset_iam_test_dataset,device,'IAM HW', n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFLaBqYir7Jv",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Qud71chdZFG"
      },
      "outputs": [],
      "source": [
        "def plot_iam_reconstructions(encoder, decoder, test_dataset, device, dataset_name, n=10):\n",
        "    wandb_imgs = list()\n",
        "    wandb_rec_imgs = list()\n",
        "    my_table = wandb.Table(columns=[\"Original\", \"Reconstruction\"])\n",
        "    plt.figure(figsize=(16, 4.5))\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        _, img, _ = test_dataset[i]\n",
        "        img = img.unsqueeze(0).to(device)\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        with torch.no_grad():\n",
        "            rec_img = decoder(encoder(img))\n",
        "        plt.imshow(img.cpu().squeeze().numpy().T, cmap='gist_gray')  # for MNIST remove the transpose\n",
        "        #   plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray') # for MNIST remove the transpose\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        if i == n // 2:\n",
        "            ax.set_title('Original images')\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(rec_img.cpu().squeeze().numpy().T, cmap='gist_gray')  # for MNIST remove the transpose\n",
        "        #   plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  #for MNIST remove the transpose\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        if i == n // 2:\n",
        "            ax.set_title('Reconstructed images')\n",
        "        my_table.add_data(wandb.Image(img.cpu()), wandb.Image(rec_img.cpu()))\n",
        "        wandb_imgs.append(img.cpu())\n",
        "        wandb_rec_imgs.append(rec_img.cpu())\n",
        "    plt.show()\n",
        "    wandb.log({dataset_name: my_table})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf7ig6N1cGAU"
      },
      "outputs": [],
      "source": [
        "plot_iam_reconstructions(vae.encoder,vae.decoder,subset_iam_test_dataset,device,'IAM HW', n=10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "zAvHGaA63gPE",
        "93a6o1jq3OHs"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}